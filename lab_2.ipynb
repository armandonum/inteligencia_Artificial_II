{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22998,"status":"ok","timestamp":1724589153500,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"c4KjmUvHVadi","outputId":"89af8dc6-2675-4c44-901f-385461be8918"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6779,"status":"ok","timestamp":1724589160269,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"e4ra51F1Vi5k"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.11.2' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","import torch.onnx\n","import torch.jit\n","\n","# Verificar si se dispone de una GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1724589160270,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"4ytl3x2TYzt7"},"outputs":[],"source":["import os\n","import torch\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","from PIL import Image, UnidentifiedImageError\n","\n","class PlantDataset(Dataset):\n","    def __init__(self, root_dirs, transform=None):\n","        self.root_dirs = root_dirs\n","        self.transform = transform\n","        self.image_paths = []\n","        self.labels = []\n","\n","        # Mapeo de nombres de carpetas a etiquetas numéricas\n","\n","        self.class_map = {\n","            'achira': 0,\n","            'calanchoe': 1,\n","            'diente_de_leon': 2,\n","            'flor_de_rosa': 3,\n","            'palta': 4\n","        }\n","\n","        # Cargar todas las rutas de imágenes y sus etiquetas\n","        for root_dir in root_dirs:\n","            class_name = root_dir.split('/')[-1].lower()  # Asumimos que el nombre de la carpeta es la clase\n","            label = self.class_map[class_name]  # Obtener el label correspondiente\n","            for root, _, files in os.walk(root_dir):\n","                for file_name in files:\n","                    if file_name.endswith(('.png', '.jpg', '.jpeg')):\n","                        file_path = os.path.join(root, file_name)\n","                        self.image_paths.append(file_path)\n","                        self.labels.append(label)\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        label = self.labels[idx]\n","\n","        try:\n","            image = Image.open(img_path).convert('RGB')\n","            if self.transform:\n","                image = self.transform(image)\n","            return image, label\n","        except UnidentifiedImageError as e:\n","            print(f\"Error: No se pudo identificar la imagen en {img_path}. {e}\")\n","            return None, label  # Puedes manejar esto en tu DataLoader para omitir imágenes no válidas\n","\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1724589160271,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"BUQrjU-tY80I"},"outputs":[],"source":["# Rutas a las carpetas descomprimidas\n","root_dirs = [\n","    '/content/drive/MyDrive/IA 2/Dataset/descomprimido/achira',\n","    '/content/drive/MyDrive/IA 2/Dataset/descomprimido/calanchoe',\n","    '/content/drive/MyDrive/IA 2/Dataset/diente_de_leon',\n","    '/content/drive/MyDrive/IA 2/Dataset/descomprimido/flor_de_rosa',\n","    '/content/drive/MyDrive/IA 2/Dataset/descomprimido/palta'\n","]"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1724589160271,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"IkAufMTIY_ex"},"outputs":[],"source":["# Transformaciones para las imágenes\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1724589160272,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"sR8GmTA5gRmL"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","# Definir un collate_fn personalizado que filtra los valores None\n","def collate_fn(batch):\n","    # Filtrar los ejemplos que contienen None\n","    batch = list(filter(lambda x: x[0] is not None, batch))\n","\n","    # Si el batch queda vacío después de filtrar, devuelve un tensor vacío\n","    if len(batch) == 0:\n","        return torch.empty(0), torch.empty(0)\n","\n","    # Usar el collate por defecto para el resto\n","    return torch.utils.data.dataloader.default_collate(batch)\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":282599,"status":"ok","timestamp":1724589442855,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"EHq8sP7GYwNs","outputId":"16b9287c-df58-4ac3-d9c4-c7e0a604301d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["\n","# Crear dataset y dataloader\n","dataset = PlantDataset(root_dirs, transform=transform)\n","# Crear el DataLoader con el collate_fn personalizado\n","dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4, prefetch_factor=2, collate_fn=collate_fn)\n","\n","\n","\n","\n","#dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4, prefetch_factor=2, collate_fn=collate_fn)\n","\n","#dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4, prefetch_factor=2)\n","\n","#dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"]},{"cell_type":"markdown","metadata":{"id":"aOrS3ZX55CLZ"},"source":[]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1724589442856,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"HM8omqAv5EeX"},"outputs":[],"source":["import torch\n","from torch.utils.data import Subset\n","\n","# Asumiendo que 'dataset' es tu dataset original\n","subset_indices = torch.randperm(len(dataset))[:int(0.6* len(dataset))]\n","subset_dataset = Subset(dataset, subset_indices)\n","\n","# Crea un nuevo DataLoader usando el subset\n","subset_dataloader = DataLoader(subset_dataset, batch_size=64, shuffle=True, num_workers=4, prefetch_factor=2)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1724589442857,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"mRQOk5WRasv-"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1724589442857,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"g0PMFceP6yjF","outputId":"5cf381fc-8fee-4267-b835-4fcfe6a356fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad de datos en el subconjunto con DataLoader simple: 48028\n"]}],"source":["# Prueba con un DataLoader más simple\n","dataloader_simple = DataLoader(subset_dataset, batch_size=64, shuffle=True)\n","subset_size_simple = len(subset_dataset)\n","print(f'Cantidad de datos en el subconjunto con DataLoader simple: {subset_size_simple}')\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1724589442857,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"BVG0_asA6mj1","outputId":"7a94d712-6af8-4021-b553-0ab42d5fc2c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad total de imágenes en el dataset: 80047\n"]}],"source":["total_images = len(dataset)\n","print(f'Cantidad total de imágenes en el dataset: {total_images}')\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1724589442858,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"UIV098sKUmPE","outputId":"5f6c03a5-072c-411e-8700-9be5cbfca392"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad de datos en el subconjunto: 48028\n"]}],"source":["# Obtener y mostrar la cantidad de datos en el subconjunto\n","subset_size = len(subset_dataset)\n","print(f'Cantidad de datos en el subconjunto: {subset_size}')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1hBAw2IBF6HxvldrK1mipITYI0A1PKQuP"},"collapsed":true,"executionInfo":{"elapsed":67334,"status":"ok","timestamp":1724589510175,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"J1MvnR9OQMdL","outputId":"c9ddd509-2832-485d-d015-846264c2fe3d"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Mapeo de etiquetas a nombres de clases\n","index_to_class = {0: 'achira', 1: 'calanchoe', 2: 'diente_de_leon', 3: 'flor_de_rosa', 4: 'palta'}\n","\n","# Función para mostrar imágenes\n","def imshow(img, label):\n","    img = img / 2 + 0.5  # desnormalizar la imagen\n","    npimg = img.numpy()\n","    class_name = index_to_class.get(label.item(), 'desconocido')  # Obtener nombre de clase\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.title(f'Etiqueta: {class_name}')\n","    plt.show()\n","\n","# Iterar sobre el DataLoader\n","data_iter = iter(dataloader)\n","images, labels = next(data_iter)\n","\n","# Mostrar imágenes en un batch\n","for i in range(len(images)):\n","    imshow(images[i], labels[i])\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1724589510177,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"n8Cxq_g4ZMaV"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(128 * 128 * 3, 50)\n","        self.fc2 = nn.Linear(50, 5)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 128 * 128 * 3)  # Aplanar las imágenes\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","model = MLP()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haRvxJ02cUHj","outputId":"08e94530-baff-465b-c5a9-6ac174537d66"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cargando checkpoint...\n"]}],"source":["\n","import torch\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","# Definir el optimizador y la función de pérdida\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Configurar el entrenamiento\n","epochs = 130\n","checkpoint_interval = 5\n","train_losses = []\n","\n","# Función para calcular la precisión\n","def calculate_accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, 1)\n","    corrects = (preds == labels).sum().item()\n","    accuracy = corrects / len(labels)\n","    return accuracy\n","\n","# Cargar el estado del modelo y el optimizador desde el checkpoint\n","def load_checkpoint(checkpoint_path):\n","    checkpoint = torch.load(checkpoint_path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    start_epoch = checkpoint['epoch']\n","    return start_epoch\n","\n","# Verificar si existe un checkpoint y cargarlo\n","checkpoint_path = '/content/drive/MyDrive/IA 2/Checkpoints/mlp_checkpoint_latest.pth'\n","start_epoch = 0\n","if os.path.isfile(checkpoint_path):\n","    print(\"Cargando checkpoint...\")\n","    start_epoch = load_checkpoint(checkpoint_path)\n","    print(f\"Resumir desde la época {start_epoch}\")"]},{"cell_type":"markdown","metadata":{"id":"702gt-Wugbk3"},"source":[]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1724589510179,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"qOOB0IsAeQW8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0x5P-J08eQJd"},"outputs":[],"source":["import os\n","\n","def verify_dataset(image_paths):\n","    missing_files = [path for path in image_paths if not os.path.exists(path)]\n","    if missing_files:\n","        print(f\"Archivos faltantes: {len(missing_files)}\")\n","        for file in missing_files:\n","            print(file)\n","    else:\n","        print(\"Todos los archivos están presentes.\")\n","\n","# Llama a esta función antes de iniciar el entrenamiento\n","verify_dataset(dataset.image_paths)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1724589530080,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"u3mPq9Q4dnE1"},"outputs":[],"source":["from PIL import Image\n","import torch\n","import os\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, image_paths, labels, transform=None):\n","        self.image_paths = [path for path in image_paths if os.path.exists(path)]  # Filtrar archivos inexistentes\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img_path = self.image_paths[index]\n","        try:\n","            image = Image.open(img_path).convert('RGB')\n","            if self.transform is not None:\n","                image = self.transform(image)\n","            label = self.labels[index]\n","            return image, label\n","        except FileNotFoundError:\n","            print(f\"Archivo no encontrado: {img_path}. Saltando a la siguiente imagen.\")\n","            return None, None\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1724589530080,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"TMVyVGdNx7N1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1724589530080,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"CAwtuZ8Zx7C3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1724589530080,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"Dc9fZ6CIx61P"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":405},"executionInfo":{"elapsed":222551,"status":"error","timestamp":1724589752622,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"mSlcxTV7ZQLe","outputId":"092d8379-4049-40bc-e2ca-6f8b08b892a9"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 111/150:   1%|          | 4/751 [03:42<11:32:04, 55.59s/batch]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-3eb994c288e0>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Barra de progreso para el dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Epoch {epoch+1}/{epochs}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Inicializar lista para guardar las imágenes que no se identificaron\n","imagenes_no_identificadas = []\n","\n","# Entrenamiento\n","for epoch in range(start_epoch, epochs):\n","    model.train()\n","    running_loss = 0.0\n","    epoch_loss = 0.0\n","    epoch_accuracy = 0.0\n","\n","    # Barra de progreso para el dataloader\n","    for batch_idx, (images, labels) in enumerate(tqdm(subset_dataloader, desc=f'Epoch {epoch+1}/{epochs}', unit='batch')):\n","        try:\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            epoch_loss += loss.item()\n","            epoch_accuracy += calculate_accuracy(outputs, labels)\n","\n","        except Exception as e:\n","            # Si ocurre un error, se salta el batch y se guarda la información\n","            print(f\"Error al procesar el batch {batch_idx} de la epoch {epoch+1}: {e}\")\n","            imagenes_no_identificadas.append((epoch+1, batch_idx))\n","            continue  # Salta este batch y continúa con el siguiente\n","\n","    # Promediar la pérdida y la precisión para la época\n","    avg_loss = running_loss / len(subset_dataloader)\n","    avg_accuracy = epoch_accuracy / len(subset_dataloader)\n","    train_losses.append(avg_loss)\n","\n","    if (epoch + 1) % checkpoint_interval == 0:\n","        checkpoint = {\n","            'epoch': epoch + 1,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': avg_loss\n","        }\n","        torch.save(checkpoint, checkpoint_path)\n","        print(f\"Checkpoint guardado en {checkpoint_path}\")\n","\n","    print(f\"Epoch [{epoch+1}/{epochs}], Pérdida: {avg_loss:.4f}, Precisión: {avg_accuracy:.4f}\")\n","\n","print(\"Entrenamiento finalizado.\")\n","\n","# Mostrar imágenes no identificadas\n","if imagenes_no_identificadas:\n","    print(\"Imágenes no identificadas durante el entrenamiento:\")\n","    for epoch_num, batch_num in imagenes_no_identificadas:\n","        print(f\"Epoch {epoch_num}, Batch {batch_num}\")\n","\n","# Graficar la pérdida de entrenamiento\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_losses, label='Pérdida de Entrenamiento')\n","plt.xlabel('Epoch')\n","plt.ylabel('Pérdida')\n","plt.title('Pérdida durante el Entrenamiento')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"TmemKGglgeu6"},"source":["#continuar desde done guardo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":36,"status":"aborted","timestamp":1724589752624,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"xgm_fJcLgqjj"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"jxl7sVosgoOe"},"source":["continuar entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"oVsdru2eIjgE"},"source":["# dividir el conjunto de datos de prueba y test"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":36,"status":"aborted","timestamp":1724589752625,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"qy5e74ABIoRB"},"outputs":[],"source":["from torch.utils.data import random_split\n","\n","# Definir el tamaño del conjunto de prueba (10% del dataset)\n","test_size = int(0.5 * len(dataset))\n","train_size = len(dataset) - test_size\n","\n","# Dividir el dataset en entrenamiento y prueba\n","train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n","\n","# Crear DataLoaders para los conjuntos de entrenamiento y prueba\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, prefetch_factor=2)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, prefetch_factor=2)\n"]},{"cell_type":"markdown","metadata":{"id":"aP2MtDDZI9ER"},"source":["# Evaluar el Modelo en el Conjunto de Prueba"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":37,"status":"aborted","timestamp":1724589752627,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"-VmPsVgsI_ff"},"outputs":[],"source":["import torch\n","from sklearn.metrics import accuracy_score\n","\n","def evaluate_model(model, dataloader):\n","    model.eval()  # Poner el modelo en modo evaluación\n","    all_labels = []\n","    all_preds = []\n","\n","    with torch.no_grad():  # Desactivar el cálculo de gradientes\n","        for images, labels in dataloader:\n","            outputs = model(images)\n","            _, preds = torch.max(outputs, 1)\n","            all_labels.extend(labels.numpy())\n","            all_preds.extend(preds.numpy())\n","\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    return accuracy\n","\n","# Evaluar el modelo en el conjunto de datos de prueba\n","accuracy = evaluate_model(model, test_dataloader)\n","print(f'Precisión del modelo en el conjunto de prueba: {accuracy:.4f}')\n"]},{"cell_type":"markdown","metadata":{"id":"i1KpmmXLK30A"},"source":["# Predecir Etiquetas para Nuevas Imágenes"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":36,"status":"aborted","timestamp":1724589752627,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"Z9DM30aSK7Zt"},"outputs":[],"source":["def predict(model, image_path, transform):\n","    model.eval()\n","    image = Image.open(image_path).convert('RGB')\n","    image = transform(image).unsqueeze(0)  # Añadir una dimensión de lote\n","    with torch.no_grad():\n","        output = model(image)\n","        _, predicted_class = torch.max(output, 1)\n","    return predicted_class.item()\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":34,"status":"aborted","timestamp":1724589752628,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"UD_M2_mvLBbo"},"outputs":[],"source":["# Predecir la clase de una nueva imagen\n","new_image_path = '/content/drive/MyDrive/IA 2/img_pruebas/dienteLeon2.png'\n","predicted_class = predict(model, new_image_path, transform)\n","print(f'La clase predicha es: {predicted_class}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":34,"status":"aborted","timestamp":1724589752629,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"},"user_tz":240},"id":"hf2hPHmJZrqe"},"outputs":[],"source":["# Exportar a TorchScript\n","scripted_model = torch.jit.script(model)\n","torch.jit.save(scripted_model, \"mlp_model_scripted.pt\")\n","\n","# Exportar a ONNX\n","dummy_input = torch.randn(1, 3, 128, 128)\n","torch.onnx.export(model, dummy_input, \"mlp_model.onnx\", verbose=True)\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNMp1hZ3j3CqN6maSuD5kOC","gpuType":"T4","mount_file_id":"1e3Tfj7IQPTYucjNkA2ChKWDQw8CpnfLW","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
