{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNSE7EYCgzVG8reQ5XMFgSX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8qWYbzOB27B","executionInfo":{"status":"ok","timestamp":1724451376768,"user_tz":240,"elapsed":35512,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"}},"outputId":"a41878b7-ba05-4a42-bcdd-44b1884a7f6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import zipfile\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms, datasets, models\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from PIL import Image\n","\n"],"metadata":{"id":"Bx1q4lNuEZe7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import zipfile\n","\n","# Descomprimir los archivos ZIP en directorios específicos\n","zip_files = [\n","     '/content/drive/MyDrive/IA 2/Dataset/achira.zip',\n","        '/content/drive/MyDrive/IA 2/Dataset/palta.zip',\n","\n","    '/content/drive/MyDrive/IA 2/Dataset/flor_de_rosa.zip',\n","\n","    '/content/drive/MyDrive/IA 2/Dataset/diente_de_leon.zip',\n","    '/content/drive/MyDrive/IA 2/Dataset/calanchoe.zip'\n","]\n","extracted_dirs = ['/content/drive/MyDrive/IA 2/Dataset/']\n","\n","for zip_file in zip_files:\n","    extract_dir = zip_file.replace('.zip', '')\n","    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n","        zip_ref.extractall(extract_dir)\n","    extracted_dirs.append(extract_dir)\n"],"metadata":{"id":"YXiqA_hiy2W-","colab":{"base_uri":"https://localhost:8080/","height":339},"executionInfo":{"status":"error","timestamp":1724422298468,"user_tz":240,"elapsed":80246,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"}},"outputId":"711f0dc9-f384-47c6-82c6-d82d7869af32"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-d8c38d0d6d91>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mextract_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mextracted_dirs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1714\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mfdst_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0;34m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# Localize variable access to minimize overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","import os\n","extracted_dirs = ['/content/drive/MyDrive/IA 2/Dataset/']\n","class PlantDataset(Dataset):\n","    def __init__(self, root_dirs, transform=None):\n","        self.samples = []\n","        self.labels = []\n","        self.transform = transform\n","\n","        # Asigna etiquetas a cada clase (carpeta)\n","        for label, root_dir in enumerate(root_dirs):\n","            for img_name in os.listdir(root_dir):\n","                img_path = os.path.join(root_dir, img_name)\n","                self.samples.append(img_path)\n","                self.labels.append(label)\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.samples[idx]\n","        image = Image.open(img_path).convert('RGB')\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","# Define las transformaciones (redimensionar y normalizar)\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),  # Redimensiona las imágenes a 128x128\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Crear el dataset y el dataloader\n","train_dataset = PlantDataset(root_dirs=extracted_dirs, transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","\n","# Comprobar el número de imágenes en el dataset\n","print(f'Número total de imágenes en el dataset: {len(train_dataset)}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDfn_HYNfsKb","executionInfo":{"status":"ok","timestamp":1724419550602,"user_tz":240,"elapsed":343,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"}},"outputId":"064df6ee-ae38-4da3-81a9-63290434ed88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Número total de imágenes en el dataset: 11\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class MLP(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        return out\n","\n","# Inicializar el modelo\n","model = MLP(input_size=128*128*3, hidden_size=50, output_size=5)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model = model.to(device)\n"],"metadata":{"id":"1WIBv9veowEM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## in this part started the second test\n"],"metadata":{"id":"xqMK4Xzra3uS"}},{"cell_type":"code","source":["import os\n","import zipfile\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms, datasets\n","import matplotlib.pyplot as plt\n","from PIL import Image"],"metadata":{"id":"IlBGmTFHN6sC","executionInfo":{"status":"ok","timestamp":1724451382645,"user_tz":240,"elapsed":5887,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Descomprimir los archivos ZIP en directorios específicos\n","zip_files = [\n","    '/content/drive/MyDrive/IA 2/Dataset/achira.zip',\n","    '/content/drive/MyDrive/IA 2/Dataset/palta.zip',\n","    '/content/drive/MyDrive/IA 2/Dataset/flor_de_rosa.zip',\n","    '/content/drive/MyDrive/IA 2/Dataset/diente_de_leon.zip',\n","    '/content/drive/MyDrive/IA 2/Dataset/calanchoe.zip'\n","]\n"],"metadata":{"id":"gLwpgn_qN-WO","executionInfo":{"status":"ok","timestamp":1724451385924,"user_tz":240,"elapsed":776,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["base_extract_dir = '/content/drive/MyDrive/IA 2/Dataset/descomprimido/'\n","os.makedirs(base_extract_dir, exist_ok=True)"],"metadata":{"id":"btv0mlsaOmou","executionInfo":{"status":"ok","timestamp":1724451388583,"user_tz":240,"elapsed":397,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Lista para almacenar los directorios de extracción\n","extracted_dirs = []\n","\n","for zip_file in zip_files:\n","    extract_dir = os.path.join(base_extract_dir, os.path.basename(zip_file).replace('.zip', ''))\n","    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n","        zip_ref.extractall(extract_dir)\n","    extracted_dirs.append(extract_dir)\n"],"metadata":{"id":"FPemmZpbOFFY","colab":{"base_uri":"https://localhost:8080/","height":339},"outputId":"586cceee-f920-4581-d42c-da6f46d95fc9"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-a493c0337011>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mextract_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_extract_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mextracted_dirs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1714\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mfdst_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0;34m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# Localize variable access to minimize overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Dataset personalizado\n","class PlantDataset(Dataset):\n","    def __init__(self, root_dirs, transform=None):\n","        self.samples = []\n","        self.labels = []\n","        self.transform = transform\n","\n","        # Asignar etiquetas a cada clase (carpeta)\n","        for label, root_dir in enumerate(root_dirs):\n","            for subdir, dirs, files in os.walk(root_dir):\n","                for img_name in files:\n","                    img_path = os.path.join(subdir, img_name)\n","                    if img_path.endswith(('.png', '.jpg', '.jpeg')):  # Asegurarse de que son imágenes\n","                        self.samples.append(img_path)\n","                        self.labels.append(label)\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.samples[idx]\n","        image = Image.open(img_path).convert('RGB')\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label"],"metadata":{"id":"gl-5XmMAgE1p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Transformaciones (redimensionar y normalizar)\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),  # Redimensionar las imágenes a 128x128\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"3xdl7jupgPeH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Crear el dataset y el dataloader\n","train_dataset = PlantDataset(root_dirs=extracted_dirs, transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"],"metadata":{"id":"DIRcV_uigSfT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Xbnrlu7FKZI-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verificar el número de imágenes en el dataset\n","print(f'Número total de imágenes en el dataset: {len(train_dataset)}')"],"metadata":{"id":"eucMqNslgYl8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verificar el número de imágenes en el dataset\n","print(f'Número total de imágenes en el dataset: {len(train_loader)}')"],"metadata":{"id":"vsAUbgZiga81"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# Verificar el número de imágenes en el dataset\n","print(f'Número total de imágenes en el dataset: {len(train_dataset)}')\n","print(f'Número total de imágenes en el dataset: {len(train_loader)}')\n","\n","# Definir la arquitectura del MLP\n","class MLP(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        return out\n","\n","# Inicializar el modelo\n","model = MLP(input_size=128*128*3, hidden_size=50, output_size=5)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model = model.to(device)\n","\n","# Definir el criterio y optimizador\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n"],"metadata":{"id":"1qrL4x_y7LjW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Entrenamiento\n","num_epochs = 1000\n","checkpoint_dir = '/content/drive/MyDrive/IA 2/Checkpoints/'\n","os.makedirs(checkpoint_dir, exist_ok=True)\n"],"metadata":{"id":"Ri9WSid0lOo6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","for epoch in range(num_epochs):\n","    epoch_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for images, labels in train_loader:\n","        images = images.view(images.size(0), -1).to(device)  # Aplanar las imágenes\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    if (epoch + 1) % 20 == 0:\n","        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pth')\n","        torch.save(model.state_dict(), checkpoint_path)\n","        print(f'Checkpoint guardado en epoch {epoch+1}')\n","\n","    if (epoch + 1) % 100 == 0:\n","        accuracy = 100 * correct / total\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/total:.4f}, Accuracy: {accuracy:.2f}%')\n"],"metadata":{"id":"x4ytYSm8lTkF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 1000\n","checkpoint_dir = 'checkpoints'\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","losses = []\n","\n","for epoch in range(num_epochs):\n","    epoch_loss = 0\n","    for i, (images, labels) in enumerate(train_loader):\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    losses.append(epoch_loss / len(train_loader))\n","\n","    if (epoch + 1) % 20 == 0:\n","        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pth')\n","        torch.save(model.state_dict(), checkpoint_path)\n","        print(f'Checkpoint saved at epoch {epoch+1}')\n","\n","    if (epoch + 1) % 100 == 0:\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0n74EAjExLG","executionInfo":{"status":"ok","timestamp":1724347094769,"user_tz":240,"elapsed":350393,"user":{"displayName":"Armando Nuñez Condori","userId":"10465107852615588067"}},"outputId":"b17094e4-ae7f-4f85-d49c-8d08447f1387"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Checkpoint saved at epoch 20\n","Checkpoint saved at epoch 40\n","Checkpoint saved at epoch 60\n","Checkpoint saved at epoch 80\n","Checkpoint saved at epoch 100\n","Epoch [100/1000], Loss: 1.6170\n","Checkpoint saved at epoch 120\n","Checkpoint saved at epoch 140\n","Checkpoint saved at epoch 160\n","Checkpoint saved at epoch 180\n","Checkpoint saved at epoch 200\n","Epoch [200/1000], Loss: 1.5352\n","Checkpoint saved at epoch 220\n","Checkpoint saved at epoch 240\n","Checkpoint saved at epoch 260\n","Checkpoint saved at epoch 280\n","Checkpoint saved at epoch 300\n","Epoch [300/1000], Loss: 1.5203\n","Checkpoint saved at epoch 320\n","Checkpoint saved at epoch 340\n","Checkpoint saved at epoch 360\n","Checkpoint saved at epoch 380\n","Checkpoint saved at epoch 400\n","Epoch [400/1000], Loss: 1.5239\n","Checkpoint saved at epoch 420\n","Checkpoint saved at epoch 440\n","Checkpoint saved at epoch 460\n","Checkpoint saved at epoch 480\n","Checkpoint saved at epoch 500\n","Epoch [500/1000], Loss: 1.4910\n","Checkpoint saved at epoch 520\n","Checkpoint saved at epoch 540\n","Checkpoint saved at epoch 560\n","Checkpoint saved at epoch 580\n","Checkpoint saved at epoch 600\n","Epoch [600/1000], Loss: 1.4741\n","Checkpoint saved at epoch 620\n","Checkpoint saved at epoch 640\n","Checkpoint saved at epoch 660\n","Checkpoint saved at epoch 680\n","Checkpoint saved at epoch 700\n","Epoch [700/1000], Loss: 1.5511\n","Checkpoint saved at epoch 720\n","Checkpoint saved at epoch 740\n","Checkpoint saved at epoch 760\n","Checkpoint saved at epoch 780\n","Checkpoint saved at epoch 800\n","Epoch [800/1000], Loss: 1.6633\n","Checkpoint saved at epoch 820\n","Checkpoint saved at epoch 840\n","Checkpoint saved at epoch 860\n","Checkpoint saved at epoch 880\n","Checkpoint saved at epoch 900\n","Epoch [900/1000], Loss: 1.5872\n","Checkpoint saved at epoch 920\n","Checkpoint saved at epoch 940\n","Checkpoint saved at epoch 960\n","Checkpoint saved at epoch 980\n","Checkpoint saved at epoch 1000\n","Epoch [1000/1000], Loss: 1.5366\n"]}]},{"cell_type":"code","source":["# Evaluar el modelo\n","model.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for images, labels in train_loader:\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * correct / total\n","print(f'Accuracy of the model on the train images: {accuracy:.2f}%')\n","\n","# Visualizar algunas predicciones\n","def imshow(img, title):\n","    img = img / 2 + 0.5  # Desnormalizar\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.title(title)\n","    plt.show()\n","\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","outputs = model(images)\n","_, predicted = torch.max(outputs, 1)\n","\n","# Mostrar las imágenes con sus etiquetas predichas\n","for i in range(5):\n","    imshow(images[i], f'Predicted: {train_dataset.classes[predicted[i]]}')\n"],"metadata":{"id":"Jc1wm6cPuEhB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(losses)\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss Over Time')\n","plt.show()\n"],"metadata":{"id":"jYUJqodOuIIE"},"execution_count":null,"outputs":[]}]}